<!-- Adapted from MJT http://mjt.web.engr.illinois.edu/ -->

<head>
  <title>VQA</title>
  <link rel="stylesheet" href="ssc5.css">
  <meta charset="UTF-8"> <!-- THIS IS FOR YOU, MIRO -->
</head>

<body>
  
  <div class="left">
  </div>

    <!-- <br clear="all"/> -->
    <div class="righter"></div>

    <div class="left">
        <hr class="sep1"/> 
        <br>
        Related Papers 
        <hr class="sep2"/>
    </div>

    <div class="right">
      <br clear="all"/>

      Learning Models for Actions and Person-Object Interactions with Transfer to Question Answering
      <br/>
      <a href="http://arunmallya.github.io/" target="_blank"> Arun Mallya</a>, <a href="http://web.engr.illinois.edu/~slazebni/" target="_blank">Svetlana Lazebnik</a>.
      <br/>
      <a href="https://arxiv.org/abs/1604.04808" target="_blank">[arXiv]</a>
      <a href="https://uofi.box.com/s/sdsvt0vm0w0k98jx1rdwa6m71lqdichp" target="_blank">[poster]</a>
      <ul>
        <li> <em>European Conference on Computer Vision (ECCV)</em>, 2016.
        <li> An action prediction network that uses local and global context, trained with Multiple Instance Learning.
        <li> Application of action features for answering Visual Madlibs questions, showing the utility of expert-derived features.
      </ul>

      Solving Visual Madlibs with Multiple Cues
      <br/>
      <a href="http://www.tatianatommasi.com/" target="_blank">Tatiana Tommasi</a>, <a href="http://arunmallya.github.io/" target="_blank"> Arun Mallya</a>, Bryan Plummer, <a href="http://web.engr.illinois.edu/~slazebni/" target="_blank">Svetlana Lazebnik</a>, <a href="http://acberg.com/" target="_blank">Alex Berg</a>, <a href="http://tamaraberg.com/" target="_blank">Tamara Berg</a>.
      <br/>
      <a href="https://arxiv.org/abs/1608.03410" target="_blank">[arXiv]</a>
      <ul>
        <li> <em>British Machine Vision Conference (BMVC)</em>, 2016.
        <li> An extension of the above work to use Scene, Action, Attribute features on Visual Madlibs.
        <li> Improvement in accuracy for all question types, along with interpretable model decisions due to high-level labels as features.
      </ul>

      Code for <a href="https://arxiv.org/abs/1606.08390" >Revisiting Visual Question Answering Baselines</a>
      <br/>
      <a href="https://github.com/arunmallya/simple-vqa" target="_blank">[code]</a>
    </div>

</body>
